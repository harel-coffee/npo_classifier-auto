{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script purpose\n",
    "- Notebook for developing `npoclass`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# # Force using CPU.\n",
    "# # https://stackoverflow.com/questions/40690598/can-keras-with-tensorflow-backend-be-forced-to-use-cpu-or-gpu-at-will\n",
    "# import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "# obtain reproducible results\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "\n",
    "# The below is necessary for starting Numpy generated random numbers\n",
    "# in a well-defined initial state.\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# The below is necessary for starting core Python generated random numbers\n",
    "# in a well-defined state.\n",
    "\n",
    "rn.seed(12345)\n",
    "\n",
    "# Force TensorFlow to use single thread. Multiple threads are a potential source of non-reproducible results.\n",
    "# For further details, see: https://stackoverflow.com/questions/42022950/\n",
    "# session_conf = tf.ConfigProto(intra_op_parallelism_threads=1,\n",
    "#                               inter_op_parallelism_threads=1)\n",
    "# Use all threads.\n",
    "session_conf = tf.ConfigProto()\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "# The below tf.set_random_seed() will make random number generation\n",
    "# in the TensorFlow backend have a well-defined initial state.\n",
    "# For further details, see:\n",
    "# https://www.tensorflow.org/api_docs/python/tf/set_random_seed\n",
    "\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "\n",
    "# Rest of code follows ...\n",
    "\n",
    "# Check GPU device.\n",
    "print(K.tensorflow_backend._get_available_gpus())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from spellchecker import SpellChecker\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "from keras.models import load_model\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_list=[str.upper(s) for s in stopwords.words('english')+list(string.punctuation)]\n",
    "# from multiprocessing import Pool # Consider multiprocessing letter.\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the loaded models and tokenizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model_broad_cat=load_model('../output/broad_category_model.h5')\n",
    "model_major_group=load_model('../output/major_group_model.h5')\n",
    "with open('../output/tokenizer.pkl', 'rb') as tokenizer_pkl:\n",
    "    tokenizer = pickle.load(tokenizer_pkl)\n",
    "with open('../output/lb_broad_cat.pkl', 'rb') as lb_broad_cat_pkl:\n",
    "    lb_broad_cat = pickle.load(lb_broad_cat_pkl)\n",
    "with open('../output/lb_major_group.pkl', 'rb') as lb_major_group_pkl:\n",
    "    lb_major_group = pickle.load(lb_major_group_pkl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load UCF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38607 25 9\n"
     ]
    }
   ],
   "source": [
    "test_file_path='../dataset/UCF/test/'\n",
    "file_list=os.listdir(test_file_path)\n",
    "df_test=pd.DataFrame()\n",
    "for file in file_list:\n",
    "    df_test=pd.concat([df_test, pd.read_pickle(test_file_path+file, compression='gzip')])\n",
    "\n",
    "# Code as 10 broad categories.\n",
    "broad_cat_dict={'I': ['A'],\n",
    "                'II': ['B'],\n",
    "                'III': ['C', 'D'],\n",
    "                'IV': ['E', 'F', 'G', 'H'],\n",
    "                'V': ['I', 'J', 'K', 'L', 'M', 'N', 'O', 'P'],\n",
    "                'VI': ['Q'],\n",
    "                'VII': ['R', 'S', 'T', 'U', 'V', 'W'],\n",
    "                'VIII': ['X'],\n",
    "                'IX': ['Y'],\n",
    "                'X': ['Z'],\n",
    "               }\n",
    "def ntee2cat(string):\n",
    "    global broad_cat_dict\n",
    "    return [s for s in broad_cat_dict.keys() if string in broad_cat_dict[s]][0]\n",
    "\n",
    "df_test['mission_prgrm_spellchk']=df_test['TAXPAYER_NAME']+' '+df_test['mission_spellchk']+' '+df_test['prgrm_dsc_spellchk'] # Using spell-checked.\n",
    "df_test['broad_cat']=df_test['NTEE1'].apply(ntee2cat)\n",
    "print(len(df_test['mission_prgrm_spellchk']), len(df_test['NTEE1'].drop_duplicates()), len(df_test['broad_cat'].drop_duplicates()))\n",
    "\n",
    "text_list_test=df_test['mission_prgrm_spellchk']\n",
    "\n",
    "# Text to sequences.\n",
    "# seq_encoding_text_test=tokenizer.texts_to_sequences(spellcheck(input_string_list))\n",
    "seq_encoding_text_test=tokenizer.texts_to_sequences(text_list_test)\n",
    "\n",
    "# Pads sequences to the same length (i.e., prepare matrix).\n",
    "x_test=pad_sequences(sequences=seq_encoding_text_test,\n",
    "                    maxlen=46612, # Max length of the sequence.\n",
    "                    dtype = \"int32\", padding = \"post\", truncating = \"post\", \n",
    "                    value = 0 # Zero is used for representing None or Unknown.\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Load label binarizers instead of fitting._\n",
    "\n",
    "<s>\n",
    "    \n",
    "```Python    \n",
    "from sklearn import preprocessing\n",
    "lb_major_group = preprocessing.LabelBinarizer()\n",
    "lb_major_group.fit(['B', 'W', 'A', 'Y', 'L', 'K', 'P', 'N', 'F', 'I', 'E', 'D', 'M', 'S', 'X', 'T', 'C', 'J', 'G', 'U', 'H', 'O', 'Q', 'R', 'V'])\n",
    "\n",
    "lb_broad_cat = preprocessing.LabelBinarizer()\n",
    "lb_broad_cat.fit(['II', 'VII', 'I', 'IX', 'V', 'IV', 'III', 'VIII', 'VI']) # The label order complies with those in trained models.\n",
    "```\n",
    "    \n",
    "</s>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use GPU.\n",
    "with tf.device('/device:GPU:1'):\n",
    "    y_prob_broad_cat=model_broad_cat.predict(x_test, verbose=1)\n",
    "    y_prob_major_group=model_major_group.predict(x_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38607/38607 [==============================] - 955s 25ms/step\n",
      "38607/38607 [==============================] - 973s 25ms/step\n"
     ]
    }
   ],
   "source": [
    "# Use CPU -- Too slow.\n",
    "# with tf.device('/device:CPU:0'):\n",
    "y_prob_broad_cat=model_broad_cat.predict(x_test, verbose=1)\n",
    "y_prob_major_group=model_major_group.predict(x_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_broad_cat = lb_broad_cat.inverse_transform(np_utils.to_categorical(y_prob_broad_cat.argmax(axis=-1)))\n",
    "y_pred_major_group = lb_major_group.inverse_transform(np_utils.to_categorical(y_prob_major_group.argmax(axis=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall ACC: 0.8323102028129614\n"
     ]
    }
   ],
   "source": [
    "df_val_broad_cat=pd.DataFrame({'pred':y_pred_broad_cat, \n",
    "                               'true':df_test['broad_cat'],\n",
    "                              })\n",
    "print('Overall ACC:', len(df_val_broad_cat[df_val_broad_cat.pred==df_val_broad_cat.true])/len(df_val_broad_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall ACC: 0.7773719791747611\n"
     ]
    }
   ],
   "source": [
    "df_val_major_group=pd.DataFrame({'pred':y_pred_major_group, \n",
    "                               'true':df_test['NTEE1'],\n",
    "                              })\n",
    "print('Overall ACC:', len(df_val_major_group[df_val_major_group.pred==df_val_major_group.true])/len(df_val_major_group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          A       0.86      0.84      0.98      0.85      0.91      0.81      4291\n",
      "          B       0.85      0.86      0.97      0.85      0.91      0.82      6419\n",
      "          C       0.71      0.65      0.99      0.68      0.80      0.63       827\n",
      "          D       0.86      0.89      1.00      0.87      0.94      0.87      1034\n",
      "          E       0.76      0.78      0.98      0.77      0.88      0.75      2307\n",
      "          F       0.48      0.60      0.99      0.53      0.77      0.57       543\n",
      "          G       0.68      0.60      0.99      0.64      0.77      0.57      1353\n",
      "          H       0.45      0.04      1.00      0.07      0.20      0.04       126\n",
      "          I       0.62      0.72      0.99      0.66      0.85      0.70       740\n",
      "          J       0.73      0.75      0.99      0.74      0.86      0.73      1132\n",
      "          K       0.75      0.67      1.00      0.71      0.82      0.64       522\n",
      "          L       0.80      0.70      0.99      0.75      0.83      0.67      1537\n",
      "          M       0.83      0.91      0.99      0.87      0.95      0.89      1140\n",
      "          N       0.84      0.92      0.98      0.88      0.95      0.90      3925\n",
      "          O       0.78      0.51      1.00      0.61      0.71      0.48       409\n",
      "          P       0.58      0.68      0.97      0.62      0.81      0.64      2318\n",
      "          Q       0.36      0.34      0.99      0.35      0.58      0.31       436\n",
      "          R       0.37      0.26      1.00      0.30      0.51      0.24       257\n",
      "          S       0.83      0.78      0.98      0.80      0.87      0.75      3603\n",
      "          T       0.51      0.25      1.00      0.34      0.50      0.23       541\n",
      "          U       0.45      0.20      1.00      0.28      0.45      0.19       225\n",
      "          V       0.00      0.00      1.00      0.00      0.00      0.00        85\n",
      "          W       0.77      0.88      0.99      0.83      0.93      0.86      2038\n",
      "          X       0.73      0.70      0.99      0.71      0.83      0.68      1098\n",
      "          Y       0.84      0.89      0.99      0.86      0.94      0.87      1701\n",
      "\n",
      "avg / total       0.77      0.78      0.98      0.77      0.87      0.75     38607\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.metrics import classification_report_imbalanced\n",
    "print(classification_report_imbalanced(y_true=df_test['NTEE1'], y_pred=y_pred_major_group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          I       0.85      0.87      0.98      0.86      0.93      0.85      4291\n",
      "         II       0.88      0.83      0.98      0.86      0.90      0.80      6419\n",
      "        III       0.88      0.79      0.99      0.83      0.89      0.77      1861\n",
      "         IV       0.88      0.76      0.99      0.82      0.87      0.74      4329\n",
      "         IX       0.89      0.88      1.00      0.89      0.94      0.87      1701\n",
      "          V       0.86      0.85      0.94      0.85      0.89      0.79     11723\n",
      "         VI       0.53      0.31      1.00      0.39      0.55      0.28       436\n",
      "        VII       0.75      0.86      0.94      0.80      0.90      0.80      6749\n",
      "       VIII       0.59      0.83      0.98      0.69      0.90      0.80      1098\n",
      "\n",
      "avg / total       0.84      0.83      0.96      0.83      0.89      0.79     38607\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.metrics import classification_report_imbalanced\n",
    "print(classification_report_imbalanced(y_true=df_test['broad_cat'], y_pred=y_pred_broad_cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color=\"green\">GPU tests all passed.</font></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export for Kappa (inercoder reliabity) test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kap_major_group=pd.DataFrame([df_test['NTEE1'].tolist(), y_pred_major_group.tolist()]).T.rename(columns={0:'NTEE1', 1:'pred'})\n",
    "df_kap_major_group.to_excel('../output/df_kap_major_group.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kap_broad_cat=pd.DataFrame([df_test['broad_cat'].tolist(), y_pred_broad_cat.tolist()]).T.rename(columns={0:'broad_cat', 1:'pred'})\n",
    "df_kap_broad_cat.to_excel('../output/df_kap_broad_cat.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Develop API script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "################################### Define reproducibility ##########################\n",
    "# # Force using CPU.\n",
    "# # https://stackoverflow.com/questions/40690598/can-keras-with-tensorflow-backend-be-forced-to-use-cpu-or-gpu-at-will\n",
    "# import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "# obtain reproducible results\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "\n",
    "# The below is necessary for starting Numpy generated random numbers\n",
    "# in a well-defined initial state.\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# The below is necessary for starting core Python generated random numbers\n",
    "# in a well-defined state.\n",
    "\n",
    "rn.seed(12345)\n",
    "\n",
    "# Force TensorFlow to use single thread.\n",
    "# Multiple threads are a potential source of non-reproducible results.\n",
    "# For further details, see: https://stackoverflow.com/questions/42022950/\n",
    "\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1,\n",
    "                              inter_op_parallelism_threads=1)\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "# The below tf.set_random_seed() will make random number generation\n",
    "# in the TensorFlow backend have a well-defined initial state.\n",
    "# For further details, see:\n",
    "# https://www.tensorflow.org/api_docs/python/tf/set_random_seed\n",
    "\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "\n",
    "\n",
    "################################### Import dependencies ##########################\n",
    "from spellchecker import SpellChecker\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "from keras.models import load_model\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_list=[str.upper(s) for s in stopwords.words('english')+list(string.punctuation)]\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from multiprocessing import Pool\n",
    "p=Pool()\n",
    "\n",
    "\n",
    "################################### Load saved models and classes ##########################\n",
    "model_broad_cat=load_model('../output/broad_category_model.h5')\n",
    "model_major_group=load_model('../output/major_group_model.h5')\n",
    "with open('../output/tokenizer.pkl', 'rb') as tokenizer_pkl:\n",
    "    tokenizer = pickle.load(tokenizer_pkl)\n",
    "with open('../output/lb_broad_cat.pkl', 'rb') as lb_broad_cat_pkl:\n",
    "    lb_broad_cat = pickle.load(lb_broad_cat_pkl)\n",
    "with open('../output/lb_major_group.pkl', 'rb') as lb_major_group_pkl:\n",
    "    lb_major_group = pickle.load(lb_major_group_pkl)\n",
    "    \n",
    "# String/String list input --> a list of string token list(s) --> spellchecking (parallel) --> predict class (serial).\n",
    "\n",
    "\n",
    "################################### Define functions ##########################\n",
    "def npoclass(string_input=None):\n",
    "    ## Define local function.\n",
    "    # Spell check function. Return corrected word if unknown; return original word if known.\n",
    "    def spellcheck(input_string):\n",
    "        if type(input_string)==str:\n",
    "            word_token_list=nltk.word_tokenize(input_string)\n",
    "            return [s.upper() for s in p.map(SpellChecker().correction, word_token_list)]\n",
    "        elif type(input_string)==list:\n",
    "            word_token_list_list=[nltk.word_tokenize(string) for string in input_string]\n",
    "            word_token_list_list_chk=[]\n",
    "            for word_token_list in word_token_list_list:\n",
    "                word_token_list_list_chk+=[[s.upper() for s in p.map(SpellChecker().correction, word_token_list)]]\n",
    "            return word_token_list_list_chk\n",
    "        else:\n",
    "            raise NameError('Input must be a string or a list of strings.')\n",
    "    \n",
    "    result_dict={}\n",
    "    # Text to sequences.\n",
    "    # seq_encoding_text_test=tokenizer.texts_to_sequences(spellcheck(input_string_list))\n",
    "    seq_encoding_text=tokenizer.texts_to_sequences(spellcheck(string_input))\n",
    "    # Pads sequences to the same length (i.e., prepare matrix).\n",
    "    x_text=pad_sequences(sequences=seq_encoding_text,\n",
    "                        maxlen=46612, # Max length of the sequence.\n",
    "                        dtype = \"int32\", padding = \"post\", truncating = \"post\", \n",
    "                        value = 0 # Zero is used for representing None or Unknown.\n",
    "                         )\n",
    "    # Predict.\n",
    "    y_prob=model_major_group.predict(x_text)\n",
    "    result_dict['major_group_label']=lb_major_group.inverse_transform(np_utils.to_categorical(y_prob.argmax(axis=-1))).tolist()\n",
    "    result_dict['major_group_prob']=[s.max() for s in y_prob]\n",
    "    y_prob=model_broad_cat.predict(x_text)\n",
    "    result_dict['broad_category_label']=lb_broad_cat.inverse_transform(np_utils.to_categorical(y_prob.argmax(axis=-1))).tolist()\n",
    "    result_dict['broad_category_prob']=[s.max() for s in y_prob]\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'major_group_label': ['N', 'C'],\n",
       " 'major_group_prob': [0.0013737775, 0.0040711625],\n",
       " 'broad_category_label': ['III', 'VII'],\n",
       " 'broad_category_prob': [0.012432104, 0.007314923]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_string_list=['environment, environment, environment, environment, environment, environment', 'Greenpeace is a global, independent campaigning organization that uses peaceful protest and creative communication to expose global environmental problems and promote solutions that are essential to a green and peaceful future.']\n",
    "npoclass(input_string_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check consistency between function and direct prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[=======> **Load UCF test files.**](#load-UCF-files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 1s 6ms/step\n",
      "0.99\n"
     ]
    }
   ],
   "source": [
    "y_class_direct=lb_broad_cat.inverse_transform(np_utils.to_categorical(model_broad_cat.predict(x_test[0:100], verbose=1).argmax(axis=-1))).tolist()\n",
    "y_class_function=npoclass(text_list_test[0:100].tolist())\n",
    "df_result_broad_cat100=pd.DataFrame({'direct':y_class_direct[0:100], \n",
    "                                     'function':y_class_function['broad_category_label']})\n",
    "print(len(df_result_broad_cat100[df_result_broad_cat100.direct==df_result_broad_cat100.function])/len(df_result_broad_cat100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 4ms/step\n",
      "0.96\n"
     ]
    }
   ],
   "source": [
    "y_class_direct=lb_major_group.inverse_transform(np_utils.to_categorical(model_major_group.predict(x_test[0:100], verbose=1).argmax(axis=-1))).tolist()\n",
    "y_class_function=npoclass(text_list_test[0:100].tolist())\n",
    "df_result_major_group100=pd.DataFrame({'direct':y_class_direct[0:100], \n",
    "                                       'function':y_class_function['major_group_label']})\n",
    "print(len(df_result_major_group100[df_result_major_group100.direct==df_result_major_group100.function])/len(df_result_major_group100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
