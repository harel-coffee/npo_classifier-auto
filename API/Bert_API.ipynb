{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9xwzy6WT7mfQ"
   },
   "outputs": [],
   "source": [
    "#set up environment\n",
    "import os, torch, pickle, warnings, random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "from tqdm import tqdm, trange\n",
    "import tensorflow as tf\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from time import sleep\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "################################### Define functions ##########################\n",
    "def npoclass(inputs, gpu_core=True, n_jobs=4, model_path=None, ntee_type='bc'):\n",
    "    \n",
    "    # Set the seed value all over the place to make this reproducible.\n",
    "    seed_val = 42\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "\n",
    "    # Check model files.\n",
    "    if ntee_type=='bc' and model_path==None:\n",
    "        raise ValueError(\"Make sure model files/path are correct. Please download from https://jima.me/open/npoclass_model_bc.zip, unzip, and specifiy model_path (default set to None).\")\n",
    "    if ntee_type=='mg' and model_path==None:\n",
    "        raise ValueError(\"Make sure model files/path are correct. Please download from https://jima.me/open/npoclass_model_mg.zip, unzip, and specifiy model_path (default set to None).\")\n",
    "        \n",
    "    # Check ntee type.\n",
    "    if ntee_type=='bc':\n",
    "        le_file_name='le_broad_cat.pkl'\n",
    "    elif ntee_type=='mg':\n",
    "        le_file_name='le_major_group.pkl'\n",
    "    else:\n",
    "        raise ValueError(\"ntee_type must be 'bc' (broad category) or 'mg' (major group)\")\n",
    "\n",
    "    # Read model and label encoder, if not read.\n",
    "    global model_loaded, tokenizer_loaded, label_encoder\n",
    "    try:\n",
    "        assert model_loaded\n",
    "        assert tokenizer_loaded\n",
    "        assert label_encoder\n",
    "    except:\n",
    "        #load a pretrained model and tokenizer.\n",
    "        model_loaded = BertForSequenceClassification.from_pretrained(model_path)\n",
    "        tokenizer_loaded = BertTokenizer.from_pretrained(model_path)\n",
    "        # Read label encoder.\n",
    "        with open(model_path+le_file_name, 'rb') as label_encoder_pkl:\n",
    "            label_encoder = pickle.load(label_encoder_pkl)\n",
    "    \n",
    "    # Select acceleration method.\n",
    "    if gpu_core==True and torch.cuda.is_available():\n",
    "        print('There are %d GPU(s) available.' % torch.cuda.device_count(), 'Using GPU:',torch.cuda.get_device_name(0))\n",
    "        torch.cuda.manual_seed_all(seed_val)\n",
    "        device = torch.device('cuda')\n",
    "        model_loaded.cuda()\n",
    "    else:\n",
    "        print('No GPU acceleration available or gpu_core=False, using CPU.')\n",
    "        device = torch.device('cpu')\n",
    "        model_loaded.cpu()\n",
    "    print('Encoding inputs ...')\n",
    "    sleep(.5) # Pause a second for better printing results.\n",
    "    # Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    # Encode inputs.\n",
    "    def func_encode_string(text_string):\n",
    "        encoded_dict = tokenizer_loaded.encode_plus(text_string,\n",
    "                                                    add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                                                    max_length = 256,           # Pad & truncate all sentences.\n",
    "                                                    truncation=True,\n",
    "                                                    pad_to_max_length = True,\n",
    "                                                    return_attention_mask = True,   # Construct attn. masks.\n",
    "                                                    return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                                                   )\n",
    "        return encoded_dict\n",
    "    # Encode input string(s).\n",
    "    if type(inputs)==list:\n",
    "        encoded_outputs=Parallel(n_jobs=n_jobs, backend=\"threading\", pre_dispatch=n_jobs, verbose=1)(delayed(func_encode_string)(text_string) for text_string in inputs)\n",
    "        for encoded_output in encoded_outputs:\n",
    "            # Add the encoded sentence to the list.\n",
    "            input_ids.append(encoded_output['input_ids'])\n",
    "            # And its attention mask (simply differentiates padding from non-padding).\n",
    "            attention_masks.append(encoded_output['attention_mask'])\n",
    "    if type(inputs)==str:\n",
    "        encoded_outputs=func_encode_string(inputs)\n",
    "        input_ids=[encoded_outputs['input_ids']]\n",
    "        attention_masks=[encoded_outputs['attention_mask']]\n",
    "\n",
    "    # Convert the lists into tensors.\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "\n",
    "    # Prepare dataloader for efficient calculation.\n",
    "    batch_size = 32\n",
    "    pred_data = TensorDataset(input_ids, attention_masks)\n",
    "    pred_sampler = SequentialSampler(pred_data)\n",
    "    pred_dataloader = DataLoader(pred_data, sampler=pred_sampler, batch_size=batch_size)\n",
    "\n",
    "    # Start prediction.\n",
    "    model_loaded.eval()\n",
    "    logits_all=[]\n",
    "    print('Predicting categories ...')\n",
    "    sleep(.5) # Pause a second for better printing results.\n",
    "    for batch in tqdm(pred_dataloader):\n",
    "        # Add batch to the pre-chosen device\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask = batch\n",
    "        with torch.no_grad():\n",
    "            outputs = model_loaded(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "        logits_all+=outputs[0].tolist()\n",
    "\n",
    "    # Calculate probabilities of logitcs.\n",
    "    logits_prob=tf.nn.sigmoid(logits_all).numpy().tolist()\n",
    "    # Find the positions of max values in logits.\n",
    "    logits_max=np.argmax(logits_prob, axis=1)\n",
    "    # Transfer to labels.\n",
    "    logits_labels=label_encoder.inverse_transform(logits_max)\n",
    "    \n",
    "    # Compile results to be returned.\n",
    "    result_list=[]\n",
    "    for list_index in range(0, len(logits_labels)):\n",
    "        result_dict={}\n",
    "        result_dict['recommended']=logits_labels[list_index]\n",
    "        conf_prob=logits_prob[list_index][logits_max[list_index]]\n",
    "        if conf_prob>=.99:\n",
    "            result_dict['confidence']='high (>=.99)'\n",
    "        elif conf_prob>=.95:\n",
    "            result_dict['confidence']='medium (<.99|>=.95)'\n",
    "        else:\n",
    "            result_dict['confidence']='low (<.95)'\n",
    "        prob_dict={}\n",
    "        for label_index in range(0, len(label_encoder.classes_)):\n",
    "            prob_dict[label_encoder.classes_[label_index]]=logits_prob[list_index][label_index]\n",
    "        result_dict['probabilities']=prob_dict\n",
    "        result_list+=[result_dict]\n",
    "        \n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available. Using GPU: Quadro RTX 6000\n",
      "Encoding inputs ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=48)]: Using backend ThreadingBackend with 48 concurrent workers.\n",
      "[Parallel(n_jobs=48)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=48)]: Done 152 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=48)]: Done 402 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=48)]: Done 752 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=48)]: Done 1202 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=48)]: Done 1752 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=48)]: Done 2402 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=48)]: Done 3152 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=48)]: Done 4002 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=48)]: Done 4952 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=48)]: Done 6002 tasks      | elapsed:    5.4s\n"
     ]
    }
   ],
   "source": [
    "t=npoclass(['educators service, environment tree protection']*20000, gpu_core=True, model_path='../../npoclass_model_bc/', n_jobs=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'recommended': 'II',\n",
       "  'confidence': 'high (>=.99)',\n",
       "  'probabilities': {'I': 0.5053212642669678,\n",
       "   'II': 0.9996891021728516,\n",
       "   'III': 0.7522094249725342,\n",
       "   'IV': 0.6053230166435242,\n",
       "   'IX': 0.2062983214855194,\n",
       "   'V': 0.9766567945480347,\n",
       "   'VI': 0.270598441362381,\n",
       "   'VII': 0.8041079044342041,\n",
       "   'VIII': 0.32034310698509216}},\n",
       " {'recommended': 'II',\n",
       "  'confidence': 'high (>=.99)',\n",
       "  'probabilities': {'I': 0.5053212642669678,\n",
       "   'II': 0.9996891021728516,\n",
       "   'III': 0.7522094249725342,\n",
       "   'IV': 0.6053230166435242,\n",
       "   'IX': 0.2062983214855194,\n",
       "   'V': 0.9766567945480347,\n",
       "   'VI': 0.270598441362381,\n",
       "   'VII': 0.8041079044342041,\n",
       "   'VIII': 0.32034310698509216}},\n",
       " {'recommended': 'II',\n",
       "  'confidence': 'high (>=.99)',\n",
       "  'probabilities': {'I': 0.5053212642669678,\n",
       "   'II': 0.9996891021728516,\n",
       "   'III': 0.7522094249725342,\n",
       "   'IV': 0.6053230166435242,\n",
       "   'IX': 0.2062983214855194,\n",
       "   'V': 0.9766567945480347,\n",
       "   'VI': 0.270598441362381,\n",
       "   'VII': 0.8041079044342041,\n",
       "   'VIII': 0.32034310698509216}}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available. Using GPU: Quadro RTX 6000\n",
      "Encoding inputs ...\n",
      "Predicting categories ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 23.73it/s]\n"
     ]
    }
   ],
   "source": [
    "t=npoclass('educators service, environment tree protection', gpu_core=True, model_path='../../npoclass_model_bc/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'recommended': 'II',\n",
       "  'confidence': 'high (>=.99)',\n",
       "  'probabilities': {'I': 0.5053212642669678,\n",
       "   'II': 0.9996891021728516,\n",
       "   'III': 0.7522097826004028,\n",
       "   'IV': 0.605323076248169,\n",
       "   'IX': 0.20629839599132538,\n",
       "   'V': 0.9766567945480347,\n",
       "   'VI': 0.2705982029438019,\n",
       "   'VII': 0.8041078448295593,\n",
       "   'VIII': 0.3203430771827698}}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available. Using GPU: Quadro RTX 6000\n",
      "Encoding inputs ...\n",
      "Predicting categories ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 31.94it/s]\n"
     ]
    }
   ],
   "source": [
    "t=npoclass('educators service, environment tree protection', gpu_core=True, ntee_type='bc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "exec(requests.get('https://raw.githubusercontent.com/ma-ji/npo_classifier/master/API/npoclass.py').text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lZk4LM6k7mfd"
   },
   "outputs": [],
   "source": [
    "df_UCF_eval=pd.read_pickle('../dataset/UCF/test/df_ucf_test.pkl.gz')\n",
    "df_UCF_eval['input']= df_UCF_eval['TAXPAYER_NAME']+' '+df_UCF_eval['mission_spellchk']+' '+df_UCF_eval['prgrm_dsc_spellchk']\n",
    "\n",
    "# Code as 10 broad categories.\n",
    "broad_cat_dict={'I': ['A'],\n",
    "                'II': ['B'],\n",
    "                'III': ['C', 'D'],\n",
    "                'IV': ['E', 'F', 'G', 'H'],\n",
    "                'V': ['I', 'J', 'K', 'L', 'M', 'N', 'O', 'P'],\n",
    "                'VI': ['Q'],\n",
    "                'VII': ['R', 'S', 'T', 'U', 'V', 'W'],\n",
    "                'VIII': ['X'],\n",
    "                'IX': ['Y'],\n",
    "                'X': ['Z'],\n",
    "               }\n",
    "def ntee2cat(string):\n",
    "    global broad_cat_dict\n",
    "    return [s for s in broad_cat_dict.keys() if string in broad_cat_dict[s]][0]\n",
    "\n",
    "df_UCF_eval['broad_cat']=df_UCF_eval['NTEE1'].apply(ntee2cat)\n",
    "\n",
    "# Create sentence and encoded label lists\n",
    "sentences = df_UCF_eval.input.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available. Using GPU: Quadro RTX 6000\n",
      "Encoding inputs ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=48)]: Using backend ThreadingBackend with 48 concurrent workers.\n",
      "[Parallel(n_jobs=48)]: Done 104 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=48)]: Done 354 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=48)]: Done 704 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=48)]: Done 1154 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=48)]: Done 1704 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=48)]: Done 2354 tasks      | elapsed:   18.1s\n",
      "[Parallel(n_jobs=48)]: Done 3104 tasks      | elapsed:   24.5s\n",
      "[Parallel(n_jobs=48)]: Done 3954 tasks      | elapsed:   30.5s\n",
      "[Parallel(n_jobs=48)]: Done 4904 tasks      | elapsed:   37.4s\n",
      "[Parallel(n_jobs=48)]: Done 5954 tasks      | elapsed:   45.0s\n",
      "[Parallel(n_jobs=48)]: Done 7104 tasks      | elapsed:   54.0s\n",
      "[Parallel(n_jobs=48)]: Done 8354 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=48)]: Done 9704 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=48)]: Done 11154 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=48)]: Done 12704 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=48)]: Done 14354 tasks      | elapsed:  1.8min\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3437, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-3-37d13976b9a9>\", line 1, in <module>\n",
      "    eval_results=npoclass(sentences, model_path='../../npoclass_model_bc/', n_jobs=48)\n",
      "  File \"<string>\", line 78, in npoclass\n",
      "  File \"/root/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 1054, in __call__\n",
      "    self.retrieve()\n",
      "  File \"/root/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 933, in retrieve\n",
      "    self._output.extend(job.get(timeout=self.timeout))\n",
      "  File \"/root/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 651, in get\n",
      "    self.wait(timeout)\n",
      "  File \"/root/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 648, in wait\n",
      "    self._event.wait(timeout)\n",
      "  File \"/root/anaconda3/lib/python3.7/threading.py\", line 552, in wait\n",
      "    signaled = self._cond.wait(timeout)\n",
      "  File \"/root/anaconda3/lib/python3.7/threading.py\", line 296, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/root/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/root/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/root/anaconda3/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/root/anaconda3/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/root/anaconda3/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/root/anaconda3/lib/python3.7/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/root/anaconda3/lib/python3.7/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/root/anaconda3/lib/python3.7/posixpath.py\", line 429, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/root/anaconda3/lib/python3.7/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-37d13976b9a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meval_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnpoclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'../../npoclass_model_bc/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m48\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36mnpoclass\u001b[0;34m(inputs, gpu_core, n_jobs, model_path, ntee_type)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2060\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2061\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2062\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2062\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2063\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 2064\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   2065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2066\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1368\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1268\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             )\n\u001b[1;32m   1270\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Minimal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1125\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[0;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "eval_results=npoclass(sentences, model_path='../../npoclass_model_bc/', n_jobs=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results=npoclass(sentences, model_path='npoclass_model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_SqyKYlA7mf7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available. Using GPU: Quadro RTX 6000\n",
      "Encoding inputs ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38607/38607 [01:31<00:00, 419.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting categories ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1207/1207 [03:15<00:00,  6.17it/s]\n"
     ]
    }
   ],
   "source": [
    "eval_results=npoclass(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          I     0.9220    0.9170    0.9903    0.9195    0.9530    0.9015      4291\n",
      "         II     0.9145    0.9084    0.9831    0.9114    0.9450    0.8863      6419\n",
      "        III     0.8968    0.9151    0.9947    0.9059    0.9541    0.9030      1861\n",
      "         IV     0.8989    0.8847    0.9874    0.8917    0.9347    0.8646      4329\n",
      "         IX     0.9091    0.9353    0.9957    0.9221    0.9650    0.9257      1701\n",
      "          V     0.9034    0.9176    0.9572    0.9105    0.9372    0.8749     11723\n",
      "         VI     0.6742    0.6835    0.9962    0.6788    0.8252    0.6596       436\n",
      "        VII     0.9047    0.8822    0.9803    0.8933    0.9300    0.8564      6749\n",
      "       VIII     0.8166    0.8352    0.9945    0.8258    0.9114    0.8173      1098\n",
      "\n",
      "avg / total     0.9019    0.9018    0.9776    0.9018    0.9387    0.8749     38607\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.metrics import classification_report_imbalanced\n",
    "print(classification_report_imbalanced(y_true=df_UCF_eval.broad_cat, y_pred=[s['recommended'] for s in eval_results], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Bert_API.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
